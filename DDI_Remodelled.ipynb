{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAmk7RNMEmpA"
      },
      "outputs": [],
      "source": [
        "!pip install rdkit torch torch_geometric seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48ZkBSZf8i5l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "import time\n",
        "import traceback\n",
        "import matplotlib.pyplot as plt\n",
        "from rdkit import Chem\n",
        "import math\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from torch_geometric.nn import GATConv\n",
        "from sklearn.metrics import roc_auc_score, auc, precision_recall_curve\n",
        "from torch.optim.lr_scheduler import MultiplicativeLR\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from sklearn.manifold import TSNE\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmu5Utup8sdC"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS0YgsSr8wG7"
      },
      "outputs": [],
      "source": [
        "# Load and validate SMILES\n",
        "smiles_df = pd.read_csv(\"/content/drive/MyDrive/VRSEC/III Year/3 - 2/Mini/Teju/Databases/DDI/SMILES_Dataset.csv\")\n",
        "smiles_df = smiles_df.dropna(subset=[\"SMILES\"]).reset_index(drop=True)\n",
        "\n",
        "smiles_df['IsValid'] = smiles_df['SMILES'].apply(lambda s: Chem.MolFromSmiles(s) is not None)\n",
        "valid_smiles = smiles_df[smiles_df['IsValid']].drop(columns=['IsValid'])\n",
        "valid_smiles.to_csv('ValidSmiles.csv', index=False)\n",
        "\n",
        "# Load interaction datasets\n",
        "biosnap = pd.read_csv(\"/content/drive/MyDrive/VRSEC/III Year/3 - 2/Mini/Teju/Databases/DDI/ChCh-Miner_durgbank-chem-chem.tsv\", sep='\\t', header=None, names=['src', 'dst'])\n",
        "biosnap = biosnap.dropna().reset_index(drop=True)\n",
        "\n",
        "drugbank = pd.read_csv(\"/content/drive/MyDrive/VRSEC/III Year/3 - 2/Mini/Teju/Databases/DDI/DrugBankDDI.csv\")\n",
        "drugbank.rename(columns={\"Drug1\": \"src\", \"Drug2\": \"dst\"}, inplace=True)\n",
        "drugbank = drugbank.dropna().reset_index(drop=True)\n",
        "\n",
        "allowed = set(valid_smiles[\"DrugBank ID\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dm3dP7EC8zhk"
      },
      "outputs": [],
      "source": [
        "# Efficient filtering\n",
        "biosnap = biosnap[biosnap['src'].isin(allowed) & biosnap['dst'].isin(allowed)].reset_index(drop=True)\n",
        "drugbank = drugbank[drugbank['src'].isin(allowed) & drugbank['dst'].isin(allowed)].reset_index(drop=True)\n",
        "\n",
        "# Combine graphs\n",
        "combined_graph = pd.concat([biosnap, drugbank], ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
        "combined_graph.to_csv(\"CombinedGraph.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CweCTjf83Jy"
      },
      "outputs": [],
      "source": [
        "# Graph Analysis\n",
        "G = nx.from_pandas_edgelist(combined_graph, source='src', target='dst')\n",
        "\n",
        "print(\"Graph Summary\")\n",
        "print(f\"Nodes: {G.number_of_nodes()} | Edges: {G.number_of_edges()}\")\n",
        "print(f\"Isolated Nodes: {any(deg == 0 for _, deg in G.degree())}\")\n",
        "print(f\"Self-loops: {any(G.has_edge(n, n) for n in G.nodes())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMLobEbiA0jc"
      },
      "outputs": [],
      "source": [
        "# Convert to PyTorch Geometric format\n",
        "def prepare_pyg_data(features, graph):\n",
        "\n",
        "    unique_ids = np.unique(graph.values)\n",
        "    id_map = {name: i for i, name in enumerate(unique_ids)}\n",
        "\n",
        "    src = graph['src'].map(id_map).values\n",
        "    dst = graph['dst'].map(id_map).values\n",
        "    edge_index = torch.tensor(np.vstack((np.concatenate([src, dst]), np.concatenate([dst, src]))), dtype=torch.long)\n",
        "\n",
        "    # Sanitize features: convert to DataFrame, drop string columns, keep only numeric\n",
        "    if not isinstance(features, pd.DataFrame):\n",
        "        features = pd.DataFrame(features)\n",
        "\n",
        "    # Drop common identifier/non-numeric columns\n",
        "    features = features.drop(columns=[col for col in features.columns if col in ['DrugBank ID', 'SMILES','Unnamed: 0', 'Description', 'DrugID']], errors='ignore')\n",
        "    features = features.select_dtypes(include=[np.number])  # Keep only numeric\n",
        "\n",
        "    # ðŸ”§ Final clean up and conversion\n",
        "    features = np.nan_to_num(features.values.astype(np.float32))\n",
        "    x = torch.tensor(features, dtype=torch.float32)\n",
        "\n",
        "    return Data(x=x, edge_index=edge_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbnmoLjr85zA"
      },
      "outputs": [],
      "source": [
        "# GNN Model\n",
        "class GATNet(nn.Module):\n",
        "    def __init__(self, in_channels, hidden):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden, heads=2)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden * 2)\n",
        "        self.conv2 = GATConv(hidden * 2, hidden)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden)\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
        "        x = F.dropout(x, p=0.3, training=self.training)\n",
        "        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n",
        "        return x\n",
        "\n",
        "    def decode(self, z, edge_index):\n",
        "        return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSHAjK0a8798"
      },
      "outputs": [],
      "source": [
        "# Training & Evaluation\n",
        "def train(model, optimizer, scheduler, criterion, data, edge_label_index, edge_label):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(data.x, data.edge_index)\n",
        "    out = model.decode(z, edge_label_index).view(-1)\n",
        "    loss = criterion(out, edge_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    return loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "    z = model.encode(data.x, data.edge_index)\n",
        "    out = model.decode(z, data.edge_label_index).sigmoid()\n",
        "    return roc_auc_score(data.edge_label.cpu(), out.cpu()), out.cpu().numpy(), data.edge_label.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tsne_visualize_per_model(model, data, model_name, sample_size=1000):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model.encode(data.x, data.edge_index)\n",
        "        edge_index = data.edge_label_index\n",
        "        labels = data.edge_label.cpu().numpy()\n",
        "\n",
        "        # Sample subset\n",
        "        total_edges = edge_index.size(1)\n",
        "        sampled_idx = np.random.choice(total_edges, min(sample_size, total_edges), replace=False)\n",
        "        sampled_edge_index = edge_index[:, sampled_idx]\n",
        "        sampled_labels = labels[sampled_idx]\n",
        "\n",
        "        # Mean-pool the two node embeddings per edge\n",
        "        edge_embeddings = (z[sampled_edge_index[0]] + z[sampled_edge_index[1]]) / 2\n",
        "        edge_embeddings = edge_embeddings.cpu().numpy()\n",
        "\n",
        "        # t-SNE\n",
        "        tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "        tsne_result = tsne.fit_transform(edge_embeddings)\n",
        "\n",
        "        # Plot\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        colors = ['green' if l == 1 else 'red' for l in sampled_labels]\n",
        "        plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=colors, alpha=0.7)\n",
        "        plt.title(f\"t-SNE of GAT Interaction Embeddings: {model_name}\")\n",
        "        plt.xlabel(\"TSNE-1\")\n",
        "        plt.ylabel(\"TSNE-2\")\n",
        "        plt.legend(handles=[\n",
        "            plt.Line2D([0], [0], marker='o', color='w', label='Positive', markerfacecolor='green', markersize=8),\n",
        "            plt.Line2D([0], [0], marker='o', color='w', label='Negative', markerfacecolor='red', markersize=8)\n",
        "        ])\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"tsne_{model_name}.png\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "AlDVqmyYxbVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSPcV_g_896f"
      },
      "outputs": [],
      "source": [
        "#embedding models\n",
        "Embedding_models = {\n",
        "    'T5': (pd.read_csv(\"/content/drive/MyDrive/VRSEC/III Year/3 - 2/Mini/Teju/Databases/ImmI Embeddings/DDI Embeddings/T5/T5_SMILES_Embeddings.csv\"), combined_graph),\n",
        "    'SBERT': (pd.read_csv(\"/content/drive/MyDrive/VRSEC/III Year/3 - 2/Mini/Teju/Databases/ImmI Embeddings/DDI Embeddings/SBERT_Embeddings.csv\"), combined_graph)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x5DtcIphnPQ"
      },
      "outputs": [],
      "source": [
        "# Assuming GATNet, prepare_pyg_data, train, evaluate, Embedding_models are already defined\n",
        "lr_list =  [0.01, 0.001, 0.0001, 0.0002, 0.0003, 0.00001]\n",
        "results_pr = {}\n",
        "\n",
        "# Define the CSV file path\n",
        "csv_file_path = \"GATNet_Results.csv\"\n",
        "\n",
        "# Prepare CSV header if the file doesn't exist\n",
        "if not os.path.exists(csv_file_path):\n",
        "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerow([\"Model\", \"Learning Rate\", \"Best Validation AUC\", \"Final Test AUC\", \"PR AUC\"])\n",
        "\n",
        "for model_name, (features, graph) in Embedding_models.items():\n",
        "    print(f\"\\n Starting training for: {model_name}\")\n",
        "\n",
        "    for selected_lr in lr_list:\n",
        "        print(f\"\\n Training with Learning Rate: {selected_lr}\")\n",
        "\n",
        "        try:\n",
        "            # --- Step 1: Feature cleanup ---\n",
        "            features_df = pd.DataFrame(features)\n",
        "            features_df = features_df.drop(columns=[\n",
        "                col for col in features_df.columns if col in\n",
        "                ['DrugBank ID', 'SMILES', 'Unnamed: 0', 'Description', 'DrugID']\n",
        "            ], errors='ignore')\n",
        "            features_df = features_df.select_dtypes(include=[np.number])\n",
        "\n",
        "            if features_df.shape[0] == 0 or features_df.shape[1] == 0:\n",
        "                print(f\" Skipping LR {selected_lr} for model {model_name} â†’ Feature matrix is empty after cleaning.\")\n",
        "                continue\n",
        "\n",
        "            features_array = np.nan_to_num(features_df.values.astype(np.float32))\n",
        "\n",
        "            if np.isnan(features_array).any():\n",
        "                print(f\" Skipping LR {selected_lr} for model {model_name} â†’ Feature matrix has NaNs even after conversion.\")\n",
        "                continue\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Skipping LR {selected_lr} for model {model_name} due to feature error: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # --- Step 2: Graph preparation ---\n",
        "            data = prepare_pyg_data(features_array, graph)\n",
        "            transform = RandomLinkSplit(is_undirected=True, add_negative_train_samples=False)\n",
        "            train_data, val_data, test_data = map(lambda x: x.to('cuda' if torch.cuda.is_available() else 'cpu'), transform(data))\n",
        "\n",
        "            device = train_data.x.device\n",
        "            model = GATNet(data.num_features, 256).to(device)\n",
        "\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=selected_lr)\n",
        "            scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lambda epoch: 0.96)\n",
        "            criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "            best_val_auc = 0\n",
        "            final_test_auc = 0\n",
        "            best_scores, best_labels = None, None\n",
        "\n",
        "            for epoch in range(1, 25):\n",
        "                torch.cuda.empty_cache()\n",
        "                epoch_start = time.time()\n",
        "\n",
        "                try:\n",
        "                    # Negative sampling\n",
        "                    num_neg = min(500, train_data.edge_label_index.size(1))\n",
        "                    neg_edge = negative_sampling(\n",
        "                        edge_index=train_data.edge_index,\n",
        "                        num_nodes=train_data.num_nodes,\n",
        "                        num_neg_samples=num_neg,\n",
        "                        method='sparse'\n",
        "                    )\n",
        "\n",
        "                    if neg_edge.size(1) == 0:\n",
        "                        # print(f\" Epoch {epoch}: No negative samples, skipping.\")\n",
        "                        continue\n",
        "\n",
        "                    # Prepare training edges & labels\n",
        "                    edge_idx = torch.cat([train_data.edge_label_index, neg_edge], dim=1).to(device)\n",
        "                    labels = torch.cat([\n",
        "                        train_data.edge_label,\n",
        "                        torch.zeros(neg_edge.size(1), device=device)\n",
        "                    ])\n",
        "\n",
        "                    assert edge_idx.device == device and labels.device == device and train_data.x.device == device\n",
        "\n",
        "                    # Training\n",
        "                    loss = train(model, optimizer, scheduler, criterion, train_data, edge_idx, labels)\n",
        "\n",
        "                    if math.isnan(loss):\n",
        "                        print(f\" NaN loss at epoch {epoch}, skipping...\")\n",
        "                        break\n",
        "\n",
        "                    # Evaluation\n",
        "                    val_auc, _, _ = evaluate(model, val_data)\n",
        "                    test_auc, scores, test_labels = evaluate(model, test_data)\n",
        "\n",
        "                    # print(f\"Epoch {epoch:03d} | val_auc={val_auc:.4f}, best_auc={best_val_auc:.4f}\", flush=True)\n",
        "\n",
        "                    if val_auc > best_val_auc:\n",
        "                        best_val_auc = val_auc\n",
        "                        final_test_auc = test_auc\n",
        "                        best_scores = scores\n",
        "                        best_labels = test_labels\n",
        "                        # print(f\" Epoch {epoch:03d} [BEST] | Loss: {loss:.4f}, Val AUC: {val_auc:.4f}, Test AUC: {test_auc:.4f}\", flush=True)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\" Error inside epoch {epoch} for {model_name} with LR {selected_lr}: {type(e).__name__}: {e}\")\n",
        "                    # traceback.print_exc() # Uncomment for detailed traceback\n",
        "                    break\n",
        "\n",
        "            pr_auc = 0\n",
        "            if best_scores is not None and len(np.unique(best_labels)) > 1: # Ensure both classes are present for PR curve\n",
        "                try:\n",
        "                    tsne_visualize_per_model(model, test_data, model_name)\n",
        "                    precision, recall, _ = precision_recall_curve(best_labels, best_scores)\n",
        "                    pr_auc = auc(recall, precision)\n",
        "                except Exception as e:\n",
        "                    print(f\" Error calculating PR AUC for {model_name} with LR {selected_lr}: {e}\")\n",
        "                    pr_auc = 0 # Set PR AUC to 0 if calculation fails\n",
        "\n",
        "            else:\n",
        "                print(f\" Not enough classes for PR AUC calculation for {model_name} with LR {selected_lr}, setting PR AUC to 0.\")\n",
        "                pr_auc = 0\n",
        "\n",
        "\n",
        "            # Store results in the CSV file\n",
        "            with open(csv_file_path, 'a', newline='') as csvfile:\n",
        "                csv_writer = csv.writer(csvfile)\n",
        "                csv_writer.writerow([model_name, selected_lr, best_val_auc, final_test_auc, pr_auc])\n",
        "\n",
        "            print(f\" Results for {model_name} (LR={selected_lr}): Best Val AUC={best_val_auc:.4f}, Final Test AUC={final_test_auc:.4f}, PR AUC={pr_auc:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Skipping training for {model_name} with LR {selected_lr} due to error: {e}\")\n",
        "            # traceback.print_exc() # Uncomment for detailed traceback\n",
        "            continue\n",
        "\n",
        "print(\"\\n All models and learning rates processed. Results saved to:\", csv_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGDt_m6FH4t-"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file\n",
        "df_results = pd.read_csv(\"GATNet_Results.csv\")\n",
        "\n",
        "df_results_dropped = df_results.drop(columns=[\"Best Validation AUC\", \"PR AUC\"])\n",
        "\n",
        "# Pivot the table to make 'Learning Rate' the new columns\n",
        "df_pivot = df_results_dropped.pivot(index='Model', columns='Learning Rate', values='Final Test AUC')\n",
        "\n",
        "# Reset index to turn 'Model' into a column again\n",
        "AUC = df_pivot.reset_index()\n",
        "\n",
        "# Rename the column axis name (which is 'Learning Rate' after pivot)\n",
        "AUC = AUC.rename_axis(None, axis=1)\n",
        "\n",
        "# Display the final dataframe\n",
        "AUC.to_csv(\"GATNet_AUC.csv\", index=False)\n",
        "AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMRrEZrGGw1Z"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file\n",
        "df_results = pd.read_csv(\"GATNet_Results.csv\")\n",
        "\n",
        "# Drop the specified columns\n",
        "df_results_dropped = df_results.drop(columns=[\"Best Validation AUC\", \"Final Test AUC\"])\n",
        "\n",
        "df_results_dropped = df_results_dropped.drop_duplicates(subset=['Model', 'Learning Rate'])\n",
        "\n",
        "# Pivot the table to make 'Learning Rate' the new columns\n",
        "df_pivot = df_results_dropped.pivot(index='Model', columns='Learning Rate', values='PR AUC')\n",
        "\n",
        "# Reset index to turn 'Model' into a column again\n",
        "PR = df_pivot.reset_index()\n",
        "\n",
        "# Rename the 'index' column to 'Model'\n",
        "PR = PR.rename_axis(None, axis=1) # Remove the column axis name 'Learning Rate'\n",
        "\n",
        "# Display the final dataframe\n",
        "PR.to_csv(\"GATNet_PR.csv\", index=False)\n",
        "PR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUC = pd.read_csv(\"GATNet_AUC.csv\")\n",
        "AUC = AUC.drop([2])\n",
        "\n",
        "# Create barplot\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.barplot(x='Model' ,  y='1e-05', data=AUC ,palette=\"crest\")\n",
        "ax.set_title(\"Combined Graph - AUROC\")\n",
        "ax.set_ylabel(\"AUROC\")\n",
        "ax.set_ylim(0.7, 1)\n",
        "ax.tick_params(axis='x', rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jukjFN2IURt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: read the GATNet_PR and drop the rows of index 2\n",
        "\n",
        "import pandas as pd\n",
        "# Read the GATNet_PR CSV file\n",
        "PR = pd.read_csv(\"GATNet_PR.csv\")\n",
        "\n",
        "# Drop rows with index 2\n",
        "PR = PR.drop([2])\n",
        "\n",
        "# Display the modified dataframe\n",
        "PR"
      ],
      "metadata": {
        "id": "Tj9EtVwPZgaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PR = pd.read_csv(\"GATNet_PR.csv\")\n",
        "# Create barplot\n",
        "ax=sns.barplot(x='Model' , y= '1e-05' , data=PR ,palette=\"crest\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax.set_title('Combined Graph - AUPR')\n",
        "ax.set(ylabel='AUPR')\n",
        "ax.set_ylim(0.7,1)\n",
        "ax.tick_params(axis='x', rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C34tpFsrT4ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the dataframe to long format for plotting\n",
        "df_pr_melted = PR.melt(id_vars='Model', var_name='Learning Rate', value_name='PR AUC')\n",
        "\n",
        "# Ensure Learning Rate is treated as a categorical variable for better plotting\n",
        "df_pr_melted['Learning Rate'] = df_pr_melted['Learning Rate'].astype(str)\n",
        "\n",
        "# Create the line plot\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.lineplot(data=df_pr_melted, x='Learning Rate', y='PR AUC', hue='Model', marker='o')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title(\"PR AUC across Different Learning Rates for Each Model\")\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"PR AUC\")\n",
        "\n",
        "# Improve layout and show plot\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title=\"Model\")\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iGdCf2_fYg0U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}